{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "846b54f7-f379-4e96-807e-c42a0839578c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols_to_encode:  ['Sex', 'Embarked']\n",
      "numeric_cols:  Index(['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare'], dtype='object')\n",
      "categorical_cols:  Index(['Name', 'Sex', 'Ticket', 'Embarked'], dtype='object')\n",
      "cols_to_encode:  ['Sex', 'Embarked']\n",
      "ImputeIgnore Index(['Name', 'Ticket'], dtype='object')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "concat() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 67\u001b[0m\n\u001b[1;32m     61\u001b[0m imputer \u001b[38;5;241m=\u001b[39m IterativeImputer(estimator\u001b[38;5;241m=\u001b[39mRandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m), \n\u001b[1;32m     62\u001b[0m                            max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     65\u001b[0m imputed_df \u001b[38;5;241m=\u001b[39m imputer\u001b[38;5;241m.\u001b[39mfit_transform(to_be_imputed)\n\u001b[0;32m---> 67\u001b[0m hmmm_idk \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimputed_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcategorical_cols\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdifference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcols_to_encode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(hmmm_idk)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# after imputed, concat ImputeIgnore list\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: concat() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/datasciencedojo/datasets/refs/heads/master/titanic.csv\")\n",
    "#df.dropna()\n",
    "\n",
    "COLUMN_NA_THRESHOLD = 0.2 # if at least 20% of column is null, drop column.\n",
    "OHE_NUNIQUE_VALS = 10 # if number of unique values in column is less than this, apply OneHotEncoder.\n",
    "\n",
    "#print(df.isnull().mean())\n",
    "cleaned_df = df.loc[:, df.isnull().mean() < COLUMN_NA_THRESHOLD] # 'age' column is almost 20% brah... this is bad.. maybe  -- IterativeImputer !     one issue with this : Categorical rows to be OneHotEncoded before Imputation: now that we've done this threshold, we can basically dropna ? For example, Embarked contains 2 null values - so just drop both rows. Issue comes when there is more - we don't wanna drop more rows (imagine if Age was a Categorical instead...) \n",
    "removed_columns = df.columns.difference(cleaned_df.columns) # ^^^ We have to OneHotEncode Categorical columns in order to Impute dataframe. What if these columns contain large number of null values? ---- also look at \n",
    "\n",
    "# ^ basically the problem is, can not impute categorical data.\n",
    "# for GA, optimise IterativeImputer ?? (it can use forest etc in back)\n",
    "\n",
    "# SEPARATE NUMERIC AND CATEGORICAL DATA\n",
    "numeric_cols = cleaned_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = cleaned_df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# encode columns AFTER being imputed in order to avoid nan cols ..... encode BEFORE..? BUT: \n",
    "# dont impute columns with no null values ofc\n",
    "# if categorical, check its in cols_to_encode - otherwise just ignore / drop the row ... too much hassle \n",
    "# columns like Name and Ticket won't give many details to the imputer anyway, so we can just ignore them \n",
    "\n",
    "\n",
    "cols_to_encode = [col for col in categorical_cols if df[col].nunique() < OHE_NUNIQUE_VALS]\n",
    "print(\"cols_to_encode: \", cols_to_encode)\n",
    "\n",
    "# dropna in cols_to_encode (i.e Embarked has 2 null values - we dont want to pass that onto OHE.)\n",
    "encode_df = df[cols_to_encode].dropna()\n",
    "df = df.loc[encode_df.index] # ensure rows dropped in encode_df are dropped in df aswell.\n",
    "\n",
    "# some values in column \n",
    "encoder = OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False)\n",
    "encoded_cats = encoder.fit_transform(encode_df)\n",
    "\n",
    "\n",
    "# Convert encoded features into a DataFrame\n",
    "encoded_cat_df = pd.DataFrame(encoded_cats, \n",
    "                               columns=encoder.get_feature_names_out(cols_to_encode),\n",
    "                               index=encode_df.index)\n",
    "\n",
    "print(\"numeric_cols: \", numeric_cols)\n",
    "print(\"categorical_cols: \", categorical_cols)\n",
    "print(\"cols_to_encode: \", cols_to_encode)\n",
    "print(\"ImputeIgnore\", categorical_cols.difference(cols_to_encode))\n",
    "\n",
    "\n",
    "# CONCATENATE NUMERIC + ENCODED CATEGORICAL DATA\n",
    "to_be_imputed = pd.concat([df[numeric_cols], encoded_cat_df], axis=1)\n",
    "\n",
    "\n",
    "# IMPUTE MISSING VALUES WITH ITERATIVE IMPUTER (Using RandomForest)\n",
    "imputer = IterativeImputer(estimator=RandomForestRegressor(n_estimators=100, random_state=42), \n",
    "                           max_iter=1000, random_state=42)\n",
    "\n",
    "\n",
    "imputed_df = imputer.fit_transform(to_be_imputed)\n",
    "\n",
    "# after imputed, concat ImputeIgnore values to it and should be good\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0b28f371-bfca-45f9-be24-666f10bc048f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Embarked  \n",
       "0        0         A/5 21171   7.2500        S  \n",
       "1        0          PC 17599  71.2833        C  \n",
       "2        0  STON/O2. 3101282   7.9250        S  \n",
       "3        0            113803  53.1000        S  \n",
       "4        0            373450   8.0500        S  \n",
       "..     ...               ...      ...      ...  \n",
       "886      0            211536  13.0000        S  \n",
       "887      0            112053  30.0000        S  \n",
       "888      2        W./C. 6607  23.4500        S  \n",
       "889      0            111369  30.0000        C  \n",
       "890      0            370376   7.7500        Q  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "cleaned_df\n",
    "\n",
    "# Convert categorical features to numeric using one-hot encoding\n",
    "#pd.get_dummies(cleaned_df, columns=['Sex', 'Embarked'], drop_first=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
